{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.6\n",
      "1.0.2\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import catboost\n",
    "print(catboost.__version__)\n",
    "import sklearn\n",
    "\n",
    "print(sklearn.__version__)\n",
    "from catboost import CatBoostClassifier\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "rs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'09:58:46'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today = datetime.now().today().time().strftime('%H:%M:%S')\n",
    "str(today)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather('sampling.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>152209.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>318579.970109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1231.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>31519.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>999251.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "count     191.000000\n",
       "mean   152209.000000\n",
       "std    318579.970109\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%      1231.000000\n",
       "75%     31519.000000\n",
       "max    999251.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "missing_limit = 400000\n",
    "missing_count = df.isna().sum().sort_values(ascending=False).to_frame().reset_index()\n",
    "display(missing_count.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 160)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[missing_count.loc[missing_count[0] < 400000]['index'].to_list()]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes(exclude=[\"number\",\"bool_\"])\n",
    "df = df.drop(['customer_ID', 'S_2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enc = OrdinalEncoder()\n",
    "# ordinal_encode_D_63 = enc.fit_transform(df.select_dtypes(exclude=[\"number\",\"bool_\"]))\n",
    "# ordinal_encode_D_63 = pd.DataFrame(ordinal_encode_D_63, columns=['D_63'])\n",
    "# df['D_63'] = ordinal_encode_D_63.D_63.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750000, 157)\n",
      "(250000, 157)\n",
      "(750000, 1)\n",
      "(250000, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('target', axis = 1), df[['target']], test_size=0.25, random_state=rs)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D_64', 'D_63']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features = list(df.select_dtypes(exclude=[\"number\",\"bool_\"]).columns)\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.loc[:, cat_features] = X_train.loc[:, cat_features].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_train_x, catboost_valid_x, catboost_train_y, catboost_valid_y = train_test_split(X_train, y_train, test_size=0.25, random_state=rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D_43</th>\n",
       "      <th>S_27</th>\n",
       "      <th>D_46</th>\n",
       "      <th>S_3</th>\n",
       "      <th>S_7</th>\n",
       "      <th>D_62</th>\n",
       "      <th>D_48</th>\n",
       "      <th>D_61</th>\n",
       "      <th>P_3</th>\n",
       "      <th>D_78</th>\n",
       "      <th>...</th>\n",
       "      <th>B_28</th>\n",
       "      <th>R_11</th>\n",
       "      <th>R_10</th>\n",
       "      <th>S_16</th>\n",
       "      <th>R_8</th>\n",
       "      <th>R_7</th>\n",
       "      <th>B_24</th>\n",
       "      <th>D_75</th>\n",
       "      <th>P_4</th>\n",
       "      <th>B_23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>502202</th>\n",
       "      <td>0.059735</td>\n",
       "      <td>0.454198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.069483</td>\n",
       "      <td>0.052458</td>\n",
       "      <td>0.394483</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>0.234478</td>\n",
       "      <td>0.646616</td>\n",
       "      <td>0.005498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036401</td>\n",
       "      <td>0.003062</td>\n",
       "      <td>0.008365</td>\n",
       "      <td>0.009597</td>\n",
       "      <td>0.003773</td>\n",
       "      <td>0.003960</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.072344</td>\n",
       "      <td>0.002308</td>\n",
       "      <td>0.027627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656964</th>\n",
       "      <td>0.038633</td>\n",
       "      <td>0.494255</td>\n",
       "      <td>0.405865</td>\n",
       "      <td>0.139724</td>\n",
       "      <td>0.108579</td>\n",
       "      <td>0.034046</td>\n",
       "      <td>0.529142</td>\n",
       "      <td>0.176623</td>\n",
       "      <td>-0.018035</td>\n",
       "      <td>0.004799</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108571</td>\n",
       "      <td>0.005739</td>\n",
       "      <td>0.009965</td>\n",
       "      <td>0.003566</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>4.590338</td>\n",
       "      <td>0.009972</td>\n",
       "      <td>0.337809</td>\n",
       "      <td>0.008656</td>\n",
       "      <td>0.075300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25952</th>\n",
       "      <td>0.239731</td>\n",
       "      <td>0.266298</td>\n",
       "      <td>0.393734</td>\n",
       "      <td>0.108152</td>\n",
       "      <td>0.077640</td>\n",
       "      <td>0.120995</td>\n",
       "      <td>0.172997</td>\n",
       "      <td>0.601090</td>\n",
       "      <td>0.556809</td>\n",
       "      <td>0.003748</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254329</td>\n",
       "      <td>0.007290</td>\n",
       "      <td>0.004201</td>\n",
       "      <td>0.005898</td>\n",
       "      <td>0.006207</td>\n",
       "      <td>0.009587</td>\n",
       "      <td>0.003328</td>\n",
       "      <td>0.205489</td>\n",
       "      <td>0.007560</td>\n",
       "      <td>0.192428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500038</th>\n",
       "      <td>0.166910</td>\n",
       "      <td>0.004575</td>\n",
       "      <td>0.443789</td>\n",
       "      <td>0.504020</td>\n",
       "      <td>0.445658</td>\n",
       "      <td>0.008733</td>\n",
       "      <td>0.639058</td>\n",
       "      <td>0.729508</td>\n",
       "      <td>0.509179</td>\n",
       "      <td>0.002963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079094</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.009353</td>\n",
       "      <td>0.009928</td>\n",
       "      <td>0.006647</td>\n",
       "      <td>0.004493</td>\n",
       "      <td>0.008854</td>\n",
       "      <td>0.202941</td>\n",
       "      <td>0.957248</td>\n",
       "      <td>0.232632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329490</th>\n",
       "      <td>0.041838</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.504826</td>\n",
       "      <td>0.446329</td>\n",
       "      <td>0.344703</td>\n",
       "      <td>0.039932</td>\n",
       "      <td>0.941534</td>\n",
       "      <td>0.903026</td>\n",
       "      <td>0.695111</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219110</td>\n",
       "      <td>0.003296</td>\n",
       "      <td>0.008363</td>\n",
       "      <td>0.003048</td>\n",
       "      <td>0.001955</td>\n",
       "      <td>0.007762</td>\n",
       "      <td>0.005480</td>\n",
       "      <td>0.271459</td>\n",
       "      <td>0.005760</td>\n",
       "      <td>0.485515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941404</th>\n",
       "      <td>0.024581</td>\n",
       "      <td>0.275628</td>\n",
       "      <td>0.437053</td>\n",
       "      <td>0.130866</td>\n",
       "      <td>0.093882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.489444</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115589</td>\n",
       "      <td>0.006328</td>\n",
       "      <td>0.008995</td>\n",
       "      <td>0.009303</td>\n",
       "      <td>0.006175</td>\n",
       "      <td>0.003858</td>\n",
       "      <td>0.007433</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.020035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890776</th>\n",
       "      <td>0.038985</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.444156</td>\n",
       "      <td>0.204615</td>\n",
       "      <td>0.169270</td>\n",
       "      <td>0.064431</td>\n",
       "      <td>0.066159</td>\n",
       "      <td>0.021294</td>\n",
       "      <td>0.636985</td>\n",
       "      <td>0.002730</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012626</td>\n",
       "      <td>0.008352</td>\n",
       "      <td>0.008158</td>\n",
       "      <td>0.004195</td>\n",
       "      <td>0.006924</td>\n",
       "      <td>0.006911</td>\n",
       "      <td>0.003126</td>\n",
       "      <td>0.068623</td>\n",
       "      <td>0.004584</td>\n",
       "      <td>0.013922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343719</th>\n",
       "      <td>0.064038</td>\n",
       "      <td>0.006749</td>\n",
       "      <td>0.478148</td>\n",
       "      <td>0.149951</td>\n",
       "      <td>0.102899</td>\n",
       "      <td>0.255739</td>\n",
       "      <td>0.395968</td>\n",
       "      <td>0.786577</td>\n",
       "      <td>0.709838</td>\n",
       "      <td>0.007268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.893792</td>\n",
       "      <td>0.503240</td>\n",
       "      <td>0.004057</td>\n",
       "      <td>0.002166</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.009931</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.068859</td>\n",
       "      <td>0.002881</td>\n",
       "      <td>0.045450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43480</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.454045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.152854</td>\n",
       "      <td>0.457047</td>\n",
       "      <td>0.649644</td>\n",
       "      <td>0.553035</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123576</td>\n",
       "      <td>0.005918</td>\n",
       "      <td>0.009338</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.009951</td>\n",
       "      <td>0.003435</td>\n",
       "      <td>0.006145</td>\n",
       "      <td>0.134540</td>\n",
       "      <td>0.007459</td>\n",
       "      <td>0.224577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537114</th>\n",
       "      <td>0.089410</td>\n",
       "      <td>0.192239</td>\n",
       "      <td>0.517228</td>\n",
       "      <td>0.136560</td>\n",
       "      <td>0.107325</td>\n",
       "      <td>0.051192</td>\n",
       "      <td>0.154555</td>\n",
       "      <td>0.171134</td>\n",
       "      <td>0.633278</td>\n",
       "      <td>0.003478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033844</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.003301</td>\n",
       "      <td>0.007189</td>\n",
       "      <td>0.009424</td>\n",
       "      <td>0.006345</td>\n",
       "      <td>0.009683</td>\n",
       "      <td>0.070515</td>\n",
       "      <td>0.001607</td>\n",
       "      <td>0.015715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>562500 rows × 157 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            D_43      S_27      D_46       S_3       S_7      D_62      D_48  \\\n",
       "502202  0.059735  0.454198       NaN  0.069483  0.052458  0.394483  0.001024   \n",
       "656964  0.038633  0.494255  0.405865  0.139724  0.108579  0.034046  0.529142   \n",
       "25952   0.239731  0.266298  0.393734  0.108152  0.077640  0.120995  0.172997   \n",
       "500038  0.166910  0.004575  0.443789  0.504020  0.445658  0.008733  0.639058   \n",
       "329490  0.041838       NaN  0.504826  0.446329  0.344703  0.039932  0.941534   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "941404  0.024581  0.275628  0.437053  0.130866  0.093882       NaN  0.002190   \n",
       "890776  0.038985  0.000020  0.444156  0.204615  0.169270  0.064431  0.066159   \n",
       "343719  0.064038  0.006749  0.478148  0.149951  0.102899  0.255739  0.395968   \n",
       "43480        NaN       NaN  0.454045       NaN       NaN  0.152854  0.457047   \n",
       "537114  0.089410  0.192239  0.517228  0.136560  0.107325  0.051192  0.154555   \n",
       "\n",
       "            D_61       P_3      D_78  ...      B_28      R_11      R_10  \\\n",
       "502202  0.234478  0.646616  0.005498  ...  0.036401  0.003062  0.008365   \n",
       "656964  0.176623 -0.018035  0.004799  ...  0.108571  0.005739  0.009965   \n",
       "25952   0.601090  0.556809  0.003748  ...  0.254329  0.007290  0.004201   \n",
       "500038  0.729508  0.509179  0.002963  ...  0.079094  0.000598  0.009353   \n",
       "329490  0.903026  0.695111  0.000353  ...  0.219110  0.003296  0.008363   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "941404       NaN  0.489444  0.000104  ...  0.115589  0.006328  0.008995   \n",
       "890776  0.021294  0.636985  0.002730  ...  0.012626  0.008352  0.008158   \n",
       "343719  0.786577  0.709838  0.007268  ...  0.893792  0.503240  0.004057   \n",
       "43480   0.649644  0.553035  0.001341  ...  0.123576  0.005918  0.009338   \n",
       "537114  0.171134  0.633278  0.003478  ...  0.033844  0.000078  0.003301   \n",
       "\n",
       "            S_16       R_8       R_7      B_24      D_75       P_4      B_23  \n",
       "502202  0.009597  0.003773  0.003960  0.000065  0.072344  0.002308  0.027627  \n",
       "656964  0.003566  0.000866  4.590338  0.009972  0.337809  0.008656  0.075300  \n",
       "25952   0.005898  0.006207  0.009587  0.003328  0.205489  0.007560  0.192428  \n",
       "500038  0.009928  0.006647  0.004493  0.008854  0.202941  0.957248  0.232632  \n",
       "329490  0.003048  0.001955  0.007762  0.005480  0.271459  0.005760  0.485515  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "941404  0.009303  0.006175  0.003858  0.007433  0.006851  0.001079  0.020035  \n",
       "890776  0.004195  0.006924  0.006911  0.003126  0.068623  0.004584  0.013922  \n",
       "343719  0.002166  0.000464  0.009931  0.000852  0.068859  0.002881  0.045450  \n",
       "43480   0.003784  0.009951  0.003435  0.006145  0.134540  0.007459  0.224577  \n",
       "537114  0.007189  0.009424  0.006345  0.009683  0.070515  0.001607  0.015715  \n",
       "\n",
       "[562500 rows x 157 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catboost_train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af9287a51ec64ba6bf41848463d3c25b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8466009\ttest: 0.8471680\tbest: 0.8471680 (0)\ttotal: 483ms\tremaining: 24m 9s\n",
      "200:\tlearn: 0.8718436\ttest: 0.8710507\tbest: 0.8710507 (198)\ttotal: 43.5s\tremaining: 10m 6s\n",
      "400:\tlearn: 0.8759022\ttest: 0.8748213\tbest: 0.8748213 (400)\ttotal: 1m 25s\tremaining: 9m 15s\n",
      "600:\tlearn: 0.8780551\ttest: 0.8765600\tbest: 0.8765867 (599)\ttotal: 2m 20s\tremaining: 9m 19s\n",
      "800:\tlearn: 0.8799484\ttest: 0.8777547\tbest: 0.8778133 (788)\ttotal: 3m 5s\tremaining: 8m 30s\n",
      "1000:\tlearn: 0.8814880\ttest: 0.8785760\tbest: 0.8785760 (1000)\ttotal: 3m 53s\tremaining: 7m 46s\n",
      "1200:\tlearn: 0.8828462\ttest: 0.8789707\tbest: 0.8790507 (1184)\ttotal: 4m 42s\tremaining: 7m 2s\n",
      "1400:\tlearn: 0.8840853\ttest: 0.8793973\tbest: 0.8794507 (1395)\ttotal: 5m 31s\tremaining: 6m 18s\n",
      "1600:\tlearn: 0.8852284\ttest: 0.8796427\tbest: 0.8797013 (1588)\ttotal: 6m 20s\tremaining: 5m 32s\n",
      "1800:\tlearn: 0.8863360\ttest: 0.8799413\tbest: 0.8800053 (1775)\ttotal: 7m 8s\tremaining: 4m 45s\n",
      "2000:\tlearn: 0.8873547\ttest: 0.8802133\tbest: 0.8803520 (1966)\ttotal: 7m 58s\tremaining: 3m 58s\n",
      "2200:\tlearn: 0.8883076\ttest: 0.8803573\tbest: 0.8804000 (2144)\ttotal: 8m 48s\tremaining: 3m 11s\n",
      "2400:\tlearn: 0.8893404\ttest: 0.8803787\tbest: 0.8804533 (2390)\ttotal: 9m 38s\tremaining: 2m 24s\n",
      "2600:\tlearn: 0.8902631\ttest: 0.8806987\tbest: 0.8806987 (2600)\ttotal: 10m 27s\tremaining: 1m 36s\n",
      "2800:\tlearn: 0.8912107\ttest: 0.8809120\tbest: 0.8809120 (2797)\ttotal: 11m 18s\tremaining: 48.2s\n",
      "2999:\tlearn: 0.8921084\ttest: 0.8808213\tbest: 0.8809867 (2840)\ttotal: 12m 8s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8809866667\n",
      "bestIteration = 2840\n",
      "\n",
      "Shrink model to first 2841 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7fcc4aeabad0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'loss_function':'CrossEntropy', # objective function\n",
    "          'eval_metric':'Accuracy', # metric\n",
    "          'cat_features': cat_features,\n",
    "          'verbose': 200, # output to stdout info about training process every 200 iterations\n",
    "          'random_seed': 42,\n",
    "          'iterations': 3000,\n",
    "          'l2_leaf_reg': 5,\n",
    "          \n",
    "         }\n",
    "cbc = CatBoostClassifier(**params)\n",
    "cbc.fit(catboost_train_x, catboost_train_y, # data to train on (required parameters, unless we provide X as a pool object, will be shown below)\n",
    "          eval_set=(catboost_valid_x, catboost_valid_y), # data to validate on\n",
    "          use_best_model=True, # True if we don't want to save trees created after iteration with the best validation score\n",
    "          plot=True # True for visualization of the training process (it is not shown in a published kernel - try executing this code)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./random_forest.joblib']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pipeline, \"./random_forest.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_test = pipeline['imputer'].transform(X_test)\n",
    "pipeline['rfc'].predict(tf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_rf = joblib.load(\"./random_forest.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_rf['rfc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8744597140527057"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, pipeline['rfc'].predict(tf_test), average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc8ec5a4a564fb5001075d1b69bd0fab6e4c7967725783b97451713cbf5ce9b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
